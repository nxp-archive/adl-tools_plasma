<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="trip.prl release 1.2.2" />
<title>Plasma Development Schedule</title>
<meta name="author" content="Brian Kahne" />
<link rel="stylesheet" href="http://docutils.sourceforge.net/tools/stylesheets/default.css" type="text/css" />
</head>
<body>
<div class="document" id="plasma-development-schedule">
<h1 class="title">Plasma Development Schedule</h1>
<table class="docinfo" frame="void" rules="none">
<col class="docinfo-name" />
<col class="docinfo-content" />
<tbody valign="top">
<tr><th class="docinfo-name">Author:</th>
<td>Brian Kahne</td></tr>
<tr><th class="docinfo-name">Contact:</th>
<td><a class="first last reference" href="mailto:bkahne&#64;freescale.com">bkahne&#64;freescale.com</a></td></tr>
<tr><th class="docinfo-name">Revision:</th>
<td><tt class="literal"><span class="pre">$Id$</span></tt></td></tr>
</tbody>
</table>
<p>This document describes PLASMA's development schedule.  It consists of a series
of entries, each representing a feature to be added.  A feature is considered
complete when its functionality, documentation, and corresponding regression
tests have been committed to CVS.  The list is in chronological order but this
order may change based upon external factors.</p>
<div class="contents topic" id="contents">
<p class="topic-title"><a name="contents">Contents</a></p>
<ul class="simple">
<li><a class="reference" href="#par-block" id="id1" name="id1">Par Block</a></li>
<li><a class="reference" href="#pfor-block" id="id2" name="id2">Pfor block</a></li>
<li><a class="reference" href="#channels-basic-alt-block" id="id3" name="id3">Channels (Basic Alt block)</a></li>
<li><a class="reference" href="#looping-alt-block" id="id4" name="id4">Looping Alt Block</a></li>
<li><a class="reference" href="#spawn-operator" id="id5" name="id5">Spawn Operator</a></li>
<li><a class="reference" href="#shared-data-structures" id="id6" name="id6">Shared Data Structures</a></li>
<li><a class="reference" href="#thread-priorities" id="id7" name="id7">Thread Priorities</a></li>
<li><a class="reference" href="#support-for-multiple-processors" id="id8" name="id8">Support For Multiple Processors</a></li>
<li><a class="reference" href="#time-model" id="id9" name="id9">Time Model</a></li>
<li><a class="reference" href="#garbage-collection" id="id10" name="id10">Garbage Collection</a></li>
<li><a class="reference" href="#timeouts" id="id11" name="id11">Timeouts</a></li>
<li><a class="reference" href="#clocked-channels" id="id12" name="id12">Clocked Channels</a></li>
<li><a class="reference" href="#kernel-threads" id="id13" name="id13">Kernel Threads</a></li>
</ul>
</div>
<div class="section" id="par-block">
<h1><a class="toc-backref" href="#id1" name="par-block">Par Block</a></h1>
<p>Status:</p>
<blockquote>
Completed 4/23/2004</blockquote>
<p>Description:</p>
<blockquote>
A par block launches each of its constituent expressions as separate
threads.  It proceeds only when all threads are finished.</blockquote>
<p>Implementation:</p>
<blockquote>
<ol class="arabic simple">
<li>The block will be converted such that each expression becomes its own
subroutine.  The parameter passed in will be a structure whose members
are pointers to any variables used by the expression.</li>
<li>Each thread will be launched via a call to pCreate.  Then a call to
pWait will exist for each thread.</li>
</ol>
</blockquote>
<p>Dependencies:</p>
<blockquote>
<ol class="arabic simple">
<li>Thread library.</li>
<li>Parser is able to parse &quot;plain&quot; block structures.</li>
</ol>
</blockquote>
<p>Regressions:</p>
<blockquote>
<ol class="arabic simple">
<li>basic/par1.pa</li>
<li>basic/qsort.pa</li>
</ol>
</blockquote>
</div>
<div class="section" id="pfor-block">
<h1><a class="toc-backref" href="#id2" name="pfor-block">Pfor block</a></h1>
<p>Status:</p>
<blockquote>
Completed 4/29/2004</blockquote>
<p>Description:</p>
<blockquote>
For-loop syntax, where body of the loop is launched as a thread.  Construct
blocks until all threads are finished.</blockquote>
<p>Implementation:</p>
<blockquote>
Same as for par block, except that the argument structure is allocated on
the thread's stack structure.  Each variable declared in loop's guard is
passed by value, while everything else is passed by reference.</blockquote>
<p>Dependencies:</p>
<blockquote>
<ol class="arabic simple">
<li>Thread library.</li>
<li>Parser is able to parse &quot;plain&quot; block structures.</li>
</ol>
</blockquote>
<p>Regressions:</p>
<blockquote>
<ol class="arabic simple">
<li>basic/par2.pa</li>
<li>basic/par3.pa</li>
</ol>
</blockquote>
</div>
<div class="section" id="channels-basic-alt-block">
<h1><a class="toc-backref" href="#id3" name="channels-basic-alt-block">Channels (Basic Alt block)</a></h1>
<p>Status:</p>
<blockquote>
Completed for 5/12/2004</blockquote>
<p>Description:</p>
<blockquote>
<p>Define channel interface and implement basic alt block.  The alt block is
like a case statement, except that each condition is a channel variable and
a variable to map the channel's return value to.  The block blocks until one
of the channels has data.  It then reads that data, maps it to the variable,
and executes the code associated with that guard.</p>
<p>Basic syntax is:</p>
<pre class="literal-block">
alt {
  &lt;channel expr&gt; [ . | -&gt; ] port(&lt;value decl&gt;): ....
  [ { default block } ]
}
</pre>
</blockquote>
<p>Implementation:</p>
<blockquote>
<p>A channel will be any type that has the required interface.  This is
compile-time polymorphism, similar to how templates work.  The required
interface is as follows.  For a channel of type T:</p>
<ol class="arabic">
<li><dl class="first">
<dt><tt class="literal"><span class="pre">T</span> <span class="pre">read()</span></tt>:  Returns a value read from the channel.  Blocks if no value is</dt>
<dd>present.  Returns the last value read, until clear_ready() is called.</dd>
</dl>
</li>
<li><dl class="first">
<dt><tt class="literal"><span class="pre">T</span> <span class="pre">get()</span></tt>:  Returns a value from the channel.  Blocks if no value is</dt>
<dd>present.  Always fetches a new value.  After a call to this, read() will
return this same value.</dd>
</dl>
</li>
<li><dl class="first">
<dt><tt class="literal"><span class="pre">void</span> <span class="pre">write(T)</span></tt>:  Writes a value to the channel.  May block, depending</dt>
<dd>upon the channel definition.</dd>
</dl>
</li>
<li><p class="first"><tt class="literal"><span class="pre">bool</span> <span class="pre">ready()</span> <span class="pre">const</span></tt>:  Returns true if the channel has a value.</p>
</li>
<li><dl class="first">
<dt><tt class="literal"><span class="pre">void</span> <span class="pre">clear_ready()</span></tt>:  Clears the ready status, forcing the fetch of a new</dt>
<dd>value.</dd>
</dl>
</li>
<li><dl class="first">
<dt><tt class="literal"><span class="pre">set_notify(Thread</span> <span class="pre">*t,int</span> <span class="pre">handle)</span></tt>:  Stores the thread and handle.  When</dt>
<dd>the channel gets a value, it will wake this thread, giving it the handle.</dd>
</dl>
</li>
<li><dl class="first">
<dt><tt class="literal"><span class="pre">clear_notify()</span></tt>:  Clears the stored thread so that no notification will</dt>
<dd>take place if a value is written to the channel.</dd>
</dl>
</li>
</ol>
<p>Some details about channel implementation:</p>
<ol class="arabic">
<li><dl class="first">
<dt>Call pSleep() to block.  You must have stored a handle to the current</dt>
<dd>thread somewhere else before this call, e.g. storing it in a channel
member variable.</dd>
</dl>
</li>
<li><dl class="first">
<dt>Call pWake() to awaken a thread.  The general protocol is that the waker</dt>
<dd>clears the thread member variable of the channel and it does this
<em>before</em> the call to pWake.</dd>
</dl>
</li>
<li><dl class="first">
<dt>Call pAddReady() to add a thread to the ready queue, but not make it</dt>
<dd>active.  No switching occurs (assuming processor is locked to avoid
preemption).</dd>
</dl>
</li>
<li><dl class="first">
<dt>A call to read() or get() should clear any notification.  Thus, with an</dt>
<dd>alt block, only the channels that had set_notify() called need to have
clear_notify() called if a ready channel is found.  The actual ready
channel should not have clear_notify() called, since there could be a
blocked writer waiting to go.</dd>
</dl>
</li>
</ol>
<p>Code conversion for the alt block will be:</p>
<ol class="arabic">
<li><p class="first">Shutdown preemption.</p>
</li>
<li><dl class="first">
<dt>Loop through all channels- if anything is ready, save handle and exit</dt>
<dd>loop.  Else, call set_notify with current thread and handle (integer
index of loop).</dd>
</dl>
</li>
<li><p class="first">If nothing ready, sleep.</p>
</li>
<li><dl class="first">
<dt>Case statement on return value of sleep, or index value from loop in</dt>
<dd>(2).  Execute relevant code.</dd>
</dl>
</li>
<li><dl class="first">
<dt>Call clear_notify on all threads.  Do this within a catch(...) block,</dt>
<dd>too.</dd>
</dl>
</li>
<li><p class="first">Alt blocks consume values, i.e. they call get().</p>
</li>
</ol>
</blockquote>
<p>Dependencies:</p>
<blockquote>
<ol class="arabic">
<li><p class="first">Need channel definition</p>
</li>
<li><dl class="first">
<dt>Add <tt class="literal"><span class="pre">int</span> <span class="pre">pSleep()</span></tt>: Puts the thread to sleep.  Returns integer when thread</dt>
<dd>wakes.</dd>
</dl>
</li>
<li><p class="first">Add <tt class="literal"><span class="pre">void</span> <span class="pre">pWake(Thread</span> <span class="pre">*t,int</span> <span class="pre">h)</span></tt>:  Wakes thread, giving it h.</p>
</li>
</ol>
</blockquote>
<p>Regressions:</p>
<blockquote>
chan1 - chan9.</blockquote>
</div>
<div class="section" id="looping-alt-block">
<h1><a class="toc-backref" href="#id4" name="looping-alt-block">Looping Alt Block</a></h1>
<p>Status:</p>
<blockquote>
Completed 5/12/2004</blockquote>
<p>Description:</p>
<blockquote>
<p>Same as alt block, but allows the user to loop over a data structure.
Syntax is:</p>
<pre class="literal-block">
afor ( &lt;s1&gt; ; &lt;s2&gt; ; &lt;s3&gt; ) {
  &lt;channel expr&gt; [ . | -&gt; ] port (&lt;value decl&gt;) { &lt;body&gt; }
  [ { &lt;default block&gt; } ]
}
</pre>
<p>Only one port statement is allowed.  An iterator variable must be declared
in &lt;s1&gt;.</p>
</blockquote>
<p>Implementation:</p>
<blockquote>
Same as for alt, except that we replicate the loop condition as a for-loop
each time we deal with channnels.  If the iterator is not an integer, we
create an auxiliary vector and store the values there.  We then store the
corresponding index of the entry as the handle in each channel.</blockquote>
<p>Dependencies:</p>
<blockquote>
Completion of alt.</blockquote>
<p>Regressions:</p>
<blockquote>
<ol class="arabic simple">
<li>basic/chan4.pa</li>
<li>basic/chan5.pa</li>
<li>basic/chan6.pa</li>
<li>basic/chan7.pa</li>
</ol>
</blockquote>
</div>
<div class="section" id="spawn-operator">
<h1><a class="toc-backref" href="#id5" name="spawn-operator">Spawn Operator</a></h1>
<p>Status:</p>
<blockquote>
Completed 5/18/2004</blockquote>
<p>Description:</p>
<blockquote>
<p>Thread creation w/o synchronization, e.g.:</p>
<pre class="literal-block">
spawn { foo(1,2,3); };
</pre>
<p>Evaluates the argument (must resolve to a function or an object's member
invocation).  The argument is launched as a thread.  The return value is an
object which meets the specifications of a channel.  It will also have
additional operators for thread control:</p>
<ol class="arabic simple">
<li>wait():  Wait for thread to finish.</li>
<li>kill():  Kill thread.</li>
</ol>
<p>The object will be a special type of channel, so you can use it in an alt
block and attempts to fetch the value before the thread is finished will
result in a block.  Unlike other channels, it will only ever have a single
value, so calls to clear_ready() will be ignored.</p>
<p>Spawn should handle all ways to invoke a function:</p>
<ol class="arabic simple">
<li>Literal function call:       spawn(foo());</li>
<li>Function pointer call:       p = foo; spawn(p());</li>
<li>Method call w/reference:     spawn(a.b());</li>
<li>Method call w/pointer:       spawn(a-&gt;b());</li>
<li>Static method call:          spawn(A::b());</li>
<li>Method pointer w/reference:  p = &amp;A::b; spawn(a.*p());</li>
<li>Method pointer w/pointer:    p = &amp;A::b; spawn(a-&gt;*p());</li>
</ol>
</blockquote>
<p>Implementation:</p>
<blockquote>
<ul class="simple">
<li>Registered as a function call of a special dummy class.</li>
<li>Void functions not handled- everything returns a value.</li>
</ul>
</blockquote>
<p>Regressions:</p>
<blockquote>
<ol class="arabic simple">
<li>spawn1</li>
<li>spawn2</li>
<li>spawn3</li>
<li>spawn4</li>
</ol>
</blockquote>
</div>
<div class="section" id="shared-data-structures">
<h1><a class="toc-backref" href="#id6" name="shared-data-structures">Shared Data Structures</a></h1>
<p>Status:</p>
<blockquote>
Completed 5/20/2004</blockquote>
<p>Description:</p>
<blockquote>
Shared data structures will allow serialized access to data, i.e. mutexes
will wrap the actual data access, ensuring safe use between threads.  The
most likely syntax will be a class attribute, e.g. pMutex class ... The
public methods will then be wrapped with mutex access code.  A per-method
modifier will allow this to be disabled (will implement only if easy to do
with OpenC++).</blockquote>
<p>Implementation:</p>
<blockquote>
<p>Straightforward use of OpenC++'s example &quot;WrapperClass&quot;.</p>
<p>Variadic function support is not perfect but can be made to work.  You can't
write a true variadic function, e.g. <tt class="literal"><span class="pre">foo(const</span> <span class="pre">char</span> <span class="pre">*fmt,..)</span></tt>, because
you can't pass the variable argument list.  Instead, you must write a
va_list function directly, e.g. <tt class="literal"><span class="pre">foo(const</span> <span class="pre">char</span> <span class="pre">*fmt,va_list</span> <span class="pre">ap)</span></tt>.  Plasma
will then create a variadic version and a v_list version for you that are
wrapped with locking code.</p>
</blockquote>
<p>Regressions:</p>
<blockquote>
<ol class="arabic simple">
<li>mutex1</li>
</ol>
</blockquote>
</div>
<div class="section" id="thread-priorities">
<h1><a class="toc-backref" href="#id7" name="thread-priorities">Thread Priorities</a></h1>
<p>Status:</p>
<blockquote>
Completed 6/4/2004.</blockquote>
<p>Decription:</p>
<blockquote>
<p>A thread will be able to change its priority using a function
(pSetPriority(int)).  The lowest level of priority will be timesliced.
Otherwise, all threads of the highest priority (0) will run to completion
before any others.</p>
<p>API:</p>
<ol class="arabic simple">
<li><tt class="literal"><span class="pre">pSetPriority(int)</span></tt>:  Set current thread's priority.  Spawned threads will
run at their parents priority.</li>
<li><tt class="literal"><span class="pre">pGetPriorities()</span></tt>:  Return current thread's priority.</li>
<li><tt class="literal"><span class="pre">pLowestPriority()</span></tt>:  Lowest priority (timeslice queue).</li>
<li>New config parameter, <tt class="literal"><span class="pre">_priority_count</span></tt> in pSetup to set number of priorities.  Default is
32.</li>
<li>Optional second argument to spawn of a priority, e.g. <tt class="literal"><span class="pre">spawn(foo(),0);</span></tt></li>
<li>Optional second argument to on block of a priority, e.g. <tt class="literal"><span class="pre">on(p1,0)</span> <span class="pre">{</span> <span class="pre">...</span> <span class="pre">}</span></tt></li>
</ol>
</blockquote>
<p>Implementation:</p>
<blockquote>
<p>Array of thread queues.  Scheduler will run high priority threads first.
Timeslicing will only be turned on when running the lowest-priority threads.</p>
<p>To the user, 0 is the highest priority, but internally 0 represents the
lowest value and thus what we timeslice on.</p>
<p>The scheduler calls <tt class="literal"><span class="pre">get_ready()</span></tt>, which returns the next thread to run,
respecting priorities.</p>
<p>The <tt class="literal"><span class="pre">preempt()</span></tt> function calls <tt class="literal"><span class="pre">Processor::ts_okay()</span></tt>, which returns
false if we're in the kernel or we're in a non-timesliceable thread.</p>
</blockquote>
<p>Regressions:</p>
<blockquote>
<ul class="simple">
<li>pri1 - pri4.</li>
</ul>
</blockquote>
</div>
<div class="section" id="support-for-multiple-processors">
<h1><a class="toc-backref" href="#id8" name="support-for-multiple-processors">Support For Multiple Processors</a></h1>
<p>Status:</p>
<blockquote>
Completed 6/4/2004.</blockquote>
<p>Description:</p>
<blockquote>
<p>Users will be able to instantiate a <strong>Processor</strong> object.  A spawn
pseudo-method will allow them to launch a thread on that processor.  Using
an on-block, e.g.:</p>
<pre class="literal-block">
par {
  on(&lt;processor&gt; [,&lt;priority&gt;]) { ... }
}
</pre>
<p>will allow for a similar feature using <strong>par</strong> blocks.  Support for <strong>pfor</strong>
will also be included.</p>
</blockquote>
<p>Implementation:</p>
<blockquote>
<ul class="simple">
<li>Rename <strong>Processor</strong> to <strong>Cluster</strong>.</li>
<li>A <strong>Processor</strong> object will be a handle around <strong>Cluster</strong>.</li>
<li>A global variable will contain a pointer to the current <strong>Cluster</strong>.  Most of
the interface functions will use that value, except for some that take a
cluster.  A new interface function will return a <strong>Cluster</strong> object
pointing to the current cluster.</li>
<li>The <strong>System</strong> object will have a queue of clusters.  Each cluster will
make one pass through its threads, then pass to the next cluster.</li>
<li>Add spawn pseudo method and add support for optional second parameter
setting priority.</li>
</ul>
</blockquote>
<p>Regressions:</p>
<blockquote>
<ul class="simple">
<li>proc1 - 3.</li>
</ul>
</blockquote>
</div>
<div class="section" id="time-model">
<h1><a class="toc-backref" href="#id9" name="time-model">Time Model</a></h1>
<p>Status:</p>
<blockquote>
Completed 6/15/2004.</blockquote>
<p>Description:</p>
<blockquote>
For more information, refer to the twiki page.  In short, users may call
<strong>pDelay(&lt;n&gt;)</strong> to delay for <strong>n</strong> time units or call <strong>pBusy(&lt;n&gt;)</strong> to
consume <strong>n</strong> time cycles.  When a processor is busy, it does no other work,
whereas a delay means that a process is just waiting.</blockquote>
<p>Implementation:</p>
<blockquote>
<p>Refer to twiki page for the basic flow.  In short, time is maintained within
System.  Two priority queues (stl priority queues) exist:  One for delayed
objects and one for busy objects.  If an object called pDelay, it's added to
the delay queue and if an object called pBusy, it's added to the busy
queue.  Note that to use pBusy, you must set ConfigParms::_busyOkay or else
pBusy will not be allowed.  This disables preemption- the only task
switching will be done when calls to pDelay or pBusy are made.</p>
<p>Time model functions:</p>
<ul class="simple">
<li>pBusy():  Consumes time.</li>
<li>pDelay():  Delays a thread.</li>
<li>pTime():  Returns current time.</li>
</ul>
<p>The delay queue stores Thread objects, ordered by decreasing time (smallest
time is at the front).  The time is the sum of the starting time and the
delay size (both stored in the Thread).</p>
<p>The busy queue stores processors, also ordered by decreasing time.  The time
is the busy thread's start time + busy time.  The busy thread is identified
by finding the highest priority non-empty queue, then looking at the back.
This is the case b/c the busy thread is added back to its respective
priority queue by the pBusy routine.</p>
<p>At a given point in time, we cycle through all processors.  For each
processor, we execute all available jobs.  When no more processors exist
with jobs to run, we call System::update_time().  It looks at both queues
and chooses a new time that is the smallest of the next items on the two
queues.  This becomes the new time.  We then transfer all delayed threads
which have the same time as current back to their owning processors and add
those processors back to the ready queue.  Duplication is handled by having
Cluster::add_proc() only add a processor if its state is not &quot;Running&quot;.  We
then add back all busy processors whose time has expired.  Then we continue.</p>
<p>If a delayed thread is ready to run, but its processor is busy, we interrupt
the busy if the thread has higher priority than the busying thread.  We
record how much busy time has been consumed and re-enqueue the processor.
For the lowest priority threads, they are considered to be timesliced.  A
configuration parameter, ConfigParms::_simtimeslice, determines the
timeslice amount.  A thread of the lowest priority that is busy will
actually add itself to the busy queue using the timeslice amount.  The busy
routine itself tracks the total amount of busy time required and loops,
re-busying the thread until all time has expired.  Thus, for timesliced
threads and for interrupted threads, the routine sees that more time is
required and loops as necessary.</p>
</blockquote>
<p>Regressions:</p>
<blockquote>
<ul class="simple">
<li>time1 - 4.</li>
</ul>
</blockquote>
</div>
<div class="section" id="garbage-collection">
<h1><a class="toc-backref" href="#id10" name="garbage-collection">Garbage Collection</a></h1>
<p>Status:</p>
<blockquote>
Completed 6/17/2004.</blockquote>
<p>Description:</p>
<blockquote>
Plasma is going to have a lot of producer/consumer type code, where the
ownership of a particular piece of memory will be hard to track.  Garbage
collection will make the code much easier to understand and less error-prone.</blockquote>
<p>Implementation:</p>
<blockquote>
<p>Boehm garbage collector.  The main issue is that the collector needs to know
about all roots in the system, i.e. thread stacks.  This is accomplished as
follows:</p>
<ol class="arabic">
<li><dl class="first">
<dt>A list exists (System::_active_list) that records all active threads.</dt>
<dd>When a thread is realized, it is added to this list.  Each Thread object
has a <strong>nt</strong> and <strong>pt</strong> pointer for storing this information.  When a
thread is destroyed, it is removed from the list.</dd>
</dl>
</li>
<li><dl class="first">
<dt>In addition to the bottom of the stack, each thread records the top of</dt>
<dd>the stack.  This is set whenever a thread is swapped out by calling
Thread::setStackEnd().</dd>
</dl>
</li>
<li><dl class="first">
<dt>Whhen the collector is called, it called the function pointer</dt>
<dd>GC_push_other_roots.  This is set to the function
System::push_other_roots(), which iterates over the active list, pushing
information about the top and bottom of the stack.</dd>
</dl>
</li>
</ol>
<p>Other routines used are GC_lock(), which does nothing since we do not use
kernel threads at this point, and GC_stop_world() and GC_start_world(),
which turn preemtion off and on.</p>
</blockquote>
<p>Dependencies:</p>
<blockquote>
The main issue is getting it to handle user-threads.  It handles kernel
threads and should be able to handle user-threads, but I don't know how to
do it yet.</blockquote>
<p>Regressions:</p>
<blockquote>
No explicit tests- the rest of the regressions should test its usage.</blockquote>
</div>
<div class="section" id="timeouts">
<h1><a class="toc-backref" href="#id11" name="timeouts">Timeouts</a></h1>
<p>Status:</p>
<blockquote>
Completed 6/18/2004.</blockquote>
<p>Description:</p>
<blockquote>
Create a channel that has a backing thread which wakes up and writes to the
channel after a specified amount of time.  Use in alt blocks.</blockquote>
<p>Implementation:</p>
<blockquote>
Created the Timeout class- it's in Interface.h.  It's written entirely in
C++ so that I could hide the implementation and not have to worry about
linking Plasma code in with the rest of the thread package.</blockquote>
<p>Regressions:</p>
<blockquote>
<ul class="simple">
<li>chan12</li>
</ul>
</blockquote>
</div>
<div class="section" id="clocked-channels">
<h1><a class="toc-backref" href="#id12" name="clocked-channels">Clocked Channels</a></h1>
<p>Investigate further.  Most likely this will be a channel whose writes are
guarded by delay statements.  The delay will come from a clock object.</p>
</div>
<div class="section" id="kernel-threads">
<h1><a class="toc-backref" href="#id13" name="kernel-threads">Kernel Threads</a></h1>
<p>Status:</p>
<blockquote>
TBD</blockquote>
<p>Description:</p>
<blockquote>
Expand underlying RTOS to an M:N model, i.e. M kernel threads, each running
N user threads.  Add a placement specifier to par so that threads may be
dispatched to different kernel threads.  These kernel threads will be
identified using a pCluster object.</blockquote>
<p>Implementation:</p>
<blockquote>
<ol class="arabic">
<li><dl class="first">
<dt>Expand RTOS to handle kernel threads.  Probably use LinuxThreads.  The</dt>
<dd>RTOS code will need mutexes around critical areas.</dd>
</dl>
</li>
<li><p class="first">Create pCluster object.  Add code to spawn new kernel threads.</p>
</li>
<li><p class="first">Expand par blocks to add placement specifier, e.g.:</p>
<pre class="literal-block">
par {
  on (cluster1) { ... }
  on (cluster2) { ... }
}

The ``on (&lt;cluster name&gt;)`` block specifies a target cluster.  The
brace-delimited code is launched as the thread.
</pre>
</li>
<li><p class="first">Retrofit shared data structures with mutexes.</p>
</li>
</ol>
</blockquote>
<p>Dependencies:</p>
<blockquote>
<ol class="arabic">
<li><dl class="first">
<dt>Garbage collector needs to work with the kernel threadss.  This</dt>
<dd>shouldn't be a problem, as the Boehm collector currently supports
LinuxThreads.</dd>
</dl>
</li>
</ol>
</blockquote>
<p>Regressions:</p>
<blockquote>
TBD</blockquote>
</div>
</div>
<hr class="footer"/>
<div class="footer">
<a class="reference" href="schedule.rst">View document source</a>.
Generated on: 2004/07/22 13:18:50 CDT.
Generated by trip.prl release 1.2.2 from <a class="reference" href="http://docutils.sourceforge.net/rst.html">reStructuredText</a> source.
</div>
</body>
</html>
