
(chapter :title "Plasma Development Schedule"

   (p [This document describes PLASMA's development schedule.  It consists of a
   series of entries, each representing a feature to be added.  A feature is
   considered complete when its functionality, documentation, and corresponding
   regression tests have been committed to CVS.  The list is in chronological
   order but this order may change based upon external factors.])

   (section :title "Par Block"

      (ssection :title "Status"

          [Completed 4/23/2004]
	  
	  )

      (ssection :title "Description"

          [A par block launches each of its constituent expressions as separate
          threads.  It proceeds only when all threads are finished.]
	  
	  )

      (ssection :title "Implementation"
      
      (itemize
	    
	 (item [The block will be converted such that each expression becomes
	 its own subroutine.  The parameter passed in will be a structure whose
	 members are pointers to any variables used by the expression.])

	 (item [Each thread will be launched via a call to pCreate.  Then a call
	 to pWait will exist for each thread.])

	 )
	 
	 )
	 
      (ssection :title "Dependencies"

          (itemize 
	     
	     (item [Thread library])
	     
	     (item [Parser is able to parse "plain" block structures.])
	     
	     )
	     )

      (ssection :title "Regressions"

      (itemize
      
	 (item [basic/par1.pa])
	 
	 (item [basic/qsort.pa])
	 
	 )
	 
	 )
      
      )

   (section :title "Pfor block"

      (ssection :title "Status"

          [Completed 4/29/2004]
	  
	  )

      (ssection :title "Description"

          [For-loop syntax, where body of the loop is launched as a thread.
          Construct blocks until all threads are finished.]
	  
	  )

      (ssection :title "Implementation"

          [Same as for par block, except that the argument structure is
          allocated on the thread's stack structure.  Each variable declared in
          loop's guard is passed by value, while everything else is passed by
          reference.]
	  
	  )

      (ssection :title "Dependencies"

          (itemize 
	     (item [Thread library])
	     (item [Parser is able to parse "plain" block structures.])))
    
      (ssection :title "Regressions"
      
      (itemize
	 (item [basic/par2.pa])
	 (item [basic/par3.pa])
	 )
	 )
      )

   (section :title "Channels (Basic Alt block)"

      (ssection :title "Status"

          [Completed for 5/12/2004]
	  )	 
	  
      (ssection :title "Description"

          [Define channel interface and implement basic alt block.  The alt
          block is like a case statement, except that each condition is a
          channel variable and a variable to map the channel's return value to.
          The block blocks until one of the channels has data.  It then reads
          that data, maps it to the variable, and executes the code associated
          with that guard.]
	  
	  (p [Basic syntax is::])
	  
	  (cprog [

          alt {
            <channel expr> \[ . | -> \] port(<value decl>): ....
            \[ { default block } \]
          }

          ])

	  )
      
      (ssection :title "Implementation"

          [A channel will be any type that has the required interface.  This is
          compile-time polymorphism, similar to how templates work.  The
          required interface is as follows.  For a channel of type T:]
	  
	  (itemize

	     (item [,(code [T read()]): Returns a value read from the channel.
	     Blocks if no value is present.  Returns the last value read, until
	     ,(code [clear_ready()]) is called.])

	     (item [,(code [T get()]): Returns a value from the channel.  Blocks
	     if no value is present.  Always fetches a new value.  After a call
	     to this, ,(code [read()]) will return this same value.])

	     (item [,(code [void write(T)]): Writes a value to the channel.  May
	     block, depending upon the channel definition.])

	     (item [,(code [bool ready() const]): Returns true if the channel
	     has a value.])

	     (item [,(code [void clear_ready()]): Clears the ready status,
	     forcing the fetch of a new value.])

	     (item [,(code [set_notify(Thread *t,int handle)]): Stores the
	     thread and handle.  When the channel gets a value, it will wake
	     this thread, giving it the handle.])

	     (item [,(code [clear_notify()]): Clears the stored thread so that
	     no notification will take place if a value is written to the
	     channel.])
	     
	     )
	     
	  (p [Some details about channel implementation:])

	  (itemize 
	     
	     (item [Call pSleep() to block.  You must have stored a handle to
	     the current thread somewhere else before this call, e.g. storing it
	     in a channel member variable.])

	     (item [Call pWake() to awaken a thread.  The general protocol is
	     that the waker clears the thread member variable of the channel and
	     it does this *before* the call to pWake.])

	     (item [Call pAddReady() to add a thread to the ready queue, but not
	     make it active.  No switching occurs (assuming processor is locked
	     to avoid preemption).])

	     (item [A call to read() or get() should clear any notification.
	     Thus, with an alt block, only the channels that had set_notify()
	     called need to have clear_notify() called if a ready channel is
	     found.  The actual ready channel should not have clear_notify()
	     called, since there could be a blocked writer waiting to go.])
	     
	     )

	  (p [Code conversion for the alt block will be:])

	  (itemize
	     
	     (item [Shutdown preemption.])

	     (item [Loop through all channels- if anything is ready, save handle
	     and exit loop.  Else, call set_notify with current thread and
	     handle (integer index of loop).])

	     (item [If nothing ready, sleep.])

	     (item [Case statement on return value of sleep, or index value from
	     loop in (2).  Execute relevant code.])

	     (item [Call clear_notify on all threads.  Do this within a
	     catch(...) block, too.])

	     (item [Alt blocks consume values, i.e. they call get().])
	     
	     )
	     
	     )

      (ssection :title "Dependencies"

      (itemize
	 
	 (item [Need channel definition.])

	 (item [Add ,(code [int pSleep()]): Puts the thread to sleep.  Returns integer
	 when thread wakes.])

	 (item [Add ,(code [void pWake(Thread *t,int h)]): Wakes thread, giving
	 it h.])
	 
	 )
	 
	 )

      (ssection :title "Regressions"
      
      (p [chan1 - chan9.])
      
      )
      
      )

   (section :title "Looping Alt Block"

      (ssection :title "Status"
      
       [Completed 5/12/2004]
       )      
   
      (ssection :title "Description"

       [Same as alt block, but allows the user to loop over a data structure.
       Syntax is:]

       (cprog [
       
        afor ( <s1> ; <s2> ; <s3> ) {
        <channel expr> \[ . | -> \] port (<value decl>) { <body> }
        \[ { <default block> } \]
      }

      ])

      [Only one port statement is allowed.  An iterator variable must be
      declared in <s1>.]
      
      )
   
   (ssection :title "Implementation"

       [Same as for alt, except that we replicate the loop condition as a
       for-loop each time we deal with channnels.  If the iterator is not an
       integer, we create an auxiliary vector and store the values there.  We
       then store the corresponding index of the entry as the handle in each
       channel.]
       
       )
   
   (ssection :title "Dependencies"

       [Completion of alt.]

       )
   
   (ssection :title "Regressions"
   
   (itemize
      
      (item [basic/chan4.pa])
      
      (item [basic/chan5.pa])
      
      (item [basic/chan6.pa])
      
      (item [basic/chan7.pa])
      
      )
      
      )
      )

   (section :title "Spawn Operator"
   
      (ssection :title "Status"

       [Completed 5/18/2004]
       )      
      
      (ssection :title "Description"

       (p [Thread creation w/o synchronization, e.g.:])

       (cprog [

spawn { foo(1,2,3); };

       ])

       (p [Evaluates the argument (must resolve to a function or an object's
       member invocation).  The argument is launched as a thread.  The return
       value is an object which meets the specifications of a channel.  It will
       also have additional operators for thread control:])
       
       (itemize
		 
	  (item [wait():  Wait for thread to finish.])

	  (item [kill():  Kill thread.])
	  
	  )

	(p [The object will be a special type of channel, so you can use it in
	an alt block and attempts to fetch the value before the thread is
	finished will result in a block.  Unlike other channels, it will only
	ever have a single value, so calls to clear_ready() will be ignored.])
	
	(p [Spawn should handle all ways to invoke a function:])
	
	(itemize 
		     
	   (item [Literal function call:       spawn(foo());])

	   (item [Function pointer call:       p = foo; spawn(p());])

	   (item [Method call w/reference:     spawn(a.b());])

	   (item [Method call w/pointer:       spawn(a->b());])

	   (item [Static method call:          spawn(A::b());])

	   (item [Method pointer w/reference:  p = &A::b; spawn(a.*p());])

	   (item [Method pointer w/pointer:    p = &A::b; spawn(a->*p());])

	   )
	   
	   )
	   
      (ssection :title "Implementation"

         (itemize
      
	    (item [Registered as a function call of a special dummy class.])
      
	    (item [Void functions not handled- everything returns a value.])
	    
	    )
	    
      )	    

      (ssection :title "Regressions"

            (itemize
	 
	       (item [spawn1])
	       
	       (item [spawn2])

	       (item [spawn3])
	       
	       (item [spawn4])
	       )
	       
	       )	       	       
      )
   
   (section :title "Shared Data Structures"

      (ssection :title "Status"

	     [Completed 5/20/2004]
       
       )
   
      (ssection :title "Description"

       (p [Shared data structures will allow serialized access to data,
       i.e. mutexes will wrap the actual data access, ensuring safe use between
       threads.  The most likely syntax will be a class attribute, e.g. pMutex
       class ... The public methods will then be wrapped with mutex access code.
       A per-method modifier will allow this to be disabled (will implement only
       if easy to do with OpenC++).])
       
       )

       (ssection :title "Implementation"

       (p [Straightforward use of OpenC++'s example "WrapperClass".])

       (p [Variadic function support is not perfect but can be made to work.
       You can't write a true variadic function, e.g. ,(code [foo(const char
       *fmt,..)]), because you can't pass the variable argument list.  Instead,
       you must write a va_list function directly, e.g. ,(code [foo(const char
       *fmt,va_list ap)]).  Plasma will then create a variadic version and a
       v_list version for you that are wrapped with locking code.])
    
        )
   
      (ssection :title "Regressions"

	    [mutex1]
	    
	    )
   
      )
   
   (section :title "Thread Priorities"

      (ssection :title "Status"

          [Completed 6/4/2004]
	 
	 )
	  
      (ssection :title "Decription"
      
      (p [A thread will be able to change its priority using a function
      (pSetPriority(int)).  The lowest level of priority will be timesliced.
      Otherwise, all threads of the highest priority (0) will run to completion
      before any others.])

      (p [API:])
      
      (itemize 

	 (item [,(code [pSetPriority(int)]): Set current thread's priority.
	 Spawned threads will run at their parents priority.])

	 (item [,(code [pGetPriorities()]):  Return current thread's priority.])

	 (item [,(code [pLowestPriority()]):  Lowest priority (timeslice queue).])

	 (item [New config parameter, ,(code [_priority_count]) in pSetup to set
	 number of priorities.  Default is 32.])

	 (item [Optional second argument to spawn of a priority, e.g. ,(code
	 [spawn(foo(),0);])])

	 (item [Optional second argument to on block of a priority, e.g. ,(code
	 [on(p1,0) { ... }])])

	 )
	 
	 )
	 
      (ssection :title "Implementation"
	 
	 (p [Array of thread queues.  Scheduler will run high priority threads
	 first.  Timeslicing will only be turned on when running the
	 lowest-priority threads.])

         (p [To the user, 0 is the highest priority, but internally 0 represents
         the lowest value and thus what we timeslice on.])

	 (p [The scheduler calls ,(code [get_ready()]), which returns the next
	 thread to run, respecting priorities.])

	 (p [The ,(code [preempt()]) function calls ,(code
	 [Processor::ts_okay()]), which returns false if we're in the kernel or
	 we're in a non-timesliceable thread.])

	 )
	 
      (ssection :title "Regressions"
	 
	 [pri1 - pri4.]
	 
	 )
      
      )

   (section :title "Support For Multiple Processors"

      (ssection :title "Status"

          [Completed 6/4/2004]

	  )
	  
      (ssection :title "Description"

          (p [Users will be able to instantiate a ,(b [Processor]) object.  A spawn
          pseudo-method will allow them to launch a thread on that processor.
          Using an on-block, e.g.:])

	  (cprog [
	  
	  par {
	    on(<processor> \[,<priority>\]) { ... }
	  }

          ])

	  (p [will allow for a similar feature using ,(b [par]) blocks.  Support
	  for ,(b [pfor]) will also be included.])
	  
	  )

      (ssection :title "Implementation"

      (itemize
	 
	 (item [Rename ,(b [Processor]) to ,(b [Cluster]).])

	 (item [A ,(b [Processor]) object will be a handle around ,(b [Cluster]).])

	 (item [A global variable will contain a pointer to the current
	 ,(b [Cluster]).  Most of the interface functions will use that value,
	 except for some that take a cluster.  A new interface function will
	 return a ,(b [Cluster]) object pointing to the current cluster.])

	 (item [The ,(b [System]) object will have a queue of clusters.  Each
	 cluster will make one pass through its threads, then pass to the next
	 cluster.])

	 (item [Add spawn pseudo method and add support for optional second
	 parameter setting priority.])
	 
	 )
	 
	 )
      
      (section :title "Regressions"

	 [proc1 - 3])
      
      )

(section :title "Time Model"

   (ssection :title "Status"

       [Completed 6/15/2004])

   (ssection :title "Description"

       (p [For more information, refer to the twiki page.  In short, users may
       call ,(code [pDelay(<n>)]) to delay for ,(b [n]) time units or call ,(b [pBusy(<n>)])
       to consume ,(b [n]) time cycles.  When a processor is busy, it does no other
       work, whereas a delay means that a process is just waiting.])
       
       )

   (ssection :title "Implementation"

       (p [Refer to twiki page for the basic flow.  In short, time is maintained
       within System.  Two priority queues (stl priority queues) exist: One for
       delayed objects and one for busy objects.  If an object called pDelay,
       it's added to the delay queue and if an object called pBusy, it's added
       to the busy queue.  Note that to use pBusy, you must set ,(code
       [ConfigParms::_busyOkay]) or else pBusy will not be allowed.  This
       disables preemption- the only task switching will be done when calls to
       pDelay or pBusy are made.])

       (p [Time model functions:])
       
       (itemize 

	  (item [pBusy():  Consumes time.])

	  (item [pDelay():  Delays a thread.])

	  (item [pTime():  Returns current time.])
	  
	  )
	  
	  (p [The delay queue stores Thread objects, ordered by decreasing time
	  (smallest time is at the front).  The time is the sum of the starting
	  time and the delay size (both stored in the Thread).])
	  
	  (p [The busy queue stores processors, also ordered by decreasing time.
	  The time is the busy thread's start time + busy time.  The busy thread
	  is identified by finding the highest priority non-empty queue, then
	  looking at the back.  This is the case b/c the busy thread is added
	  back to its respective priority queue by the pBusy routine.])

	  (p [At a given point in time, we cycle through all processors.  For
	  each processor, we execute all available jobs.  When no more
	  processors exist with jobs to run, we call ,(code
	  [System::update_time()]).  It looks at both queues and chooses a new
	  time that is the smallest of the next items on the two queues.  This
	  becomes the new time.  We then transfer all delayed threads which have
	  the same time as current back to their owning processors and add those
	  processors back to the ready queue.  Duplication is handled by having
	  ,(code [Cluster::add_proc()]) only add a processor if its state is not
	  "Running".  We then add back all busy processors whose time has
	  expired.  Then we continue.])

	  (p [If a delayed thread is ready to run, but its processor is busy, we
	  interrupt the busy if the thread has higher priority than the busying
	  thread.  We record how much busy time has been consumed and re-enqueue
	  the processor.  For the lowest priority threads, they are considered
	  to be timesliced.  A configuration parameter,
	  ,(code [ConfigParms::_simtimeslice]), determines the timeslice amount.  A thread
	  of the lowest priority that is busy will actually add itself to the
	  busy queue using the timeslice amount.  The busy routine itself tracks
	  the total amount of busy time required and loops, re-busying the
	  thread until all time has expired.  Thus, for timesliced threads and
	  for interrupted threads, the routine sees that more time is required
	  and loops as necessary.])

	  )
   
   (ssection :title "Regressions"

       [time1 - 4]
       
       )
   
   )

   (section :title "Garbage Collection"

      (ssection :title "Status"

          [Completed 6/17/2004]
	  
	  )

      (ssection :title "Description"

	   (p [Plasma is going to have a lot of producer/consumer type code,
	   where the ownership of a particular piece of memory will be hard to
	   track.  Garbage collection will make the code much easier to
	   understand and less error-prone.])
    
        )

      (ssection :title "Implementation"

	 (p [Boehm garbage collector.  The main issue is that the collector
	 needs to know about all roots in the system, i.e. thread stacks.  This
	 is accomplished as follows:])

	 (itemize 
	    
	    (item [A list exists (,(code [System::_active_list])) that records
	    all active threads.  When a thread is realized, it is added to this
	    list.  Each Thread object has a ,(b [nt]) and ,(b [pt]) pointer for
	    storing this information.  When a thread is destroyed, it is removed
	    from the list.])

	    (item [In addition to the bottom of the stack, each thread records
	    the top of the stack.  This is set whenever a thread is swapped out
	    by calling ,(code [Thread::setStackEnd()]).])

	    (item [When the collector is called, it called the function pointer
	    GC_push_other_roots.  This is set to the function ,(code
	    [System::push_other_roots()]), which iterates over the active list,
	    pushing information about the top and bottom of the stack.])

	    (item [Other routines used are GC_lock(), which does nothing since
	    we do not use kernel threads at this point, and GC_stop_world() and
	    GC_start_world(), which turn preemtion off and on.])
	    
	    )
	 
	 )

      (ssection :title "Dependencies"

          (p [The main issue is getting it to handle user-threads.  It handles
          kernel threads and should be able to handle user-threads, but I don't
          know how to do it yet.])
	  
	  )

      (ssection :title "Regressions"

          [No explicit tests- the rest of the regressions should test its
	  usage.]
	  
	  )
      )

   (section :title "Timeouts"
   
      (ssection :title "Status"
   
      [Completed 6/18/2004]
   
      )
   
      (ssection :title "Description"
      
      (p [Create a channel that has a backing thread which wakes up and writes
      to the channel after a specified amount of time.  Use in alt blocks.])
      
      )

      (ssection :title "Implementation"
      
      (p [Created the Timeout class- it's in Interface.h.  It's written entirely
      in C++ so that I could hide the implementation and not have to worry about
      linking Plasma code in with the rest of the thread package.])
      
      )

      (ssection :title "Regressions"

          [chan12]
	  
	  )
      
      )
   
   (section :title "Clocked Channels"

      (ssection :title "Status"
   
      [Completed 8/1/2004]
   
      )
   
      (ssection :title "Description"
      
      (p [Clocked channels will be channels with knowledge of time.  Writes will
      be able to occur at anytime, but reads will only be allowed on clock
      boundaries, where the clock period is defined by a parameter to the
      constructor.])
      
      )

      (ssection :title "Implementation"
      
      (p [Implemented as a normal channel, except that a read will create a
      waking thread if we're not on a clock edge, then go to sleep.])
      
      )

      (ssection :title "Regressions"

	  [clock1- clock3]
	  
	  )
      
      )
)
