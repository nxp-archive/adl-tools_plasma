2004-06-25  Brian Kahne  <bkahne@ibmoto.com>

	* Fixed problems w/nested par blocks.  Two problems were found:
	The VarWalker class needed to overload TranslateUserPlain so that
	par and alt blocks weren't opaque.  Second, the code that we were
	producing was created as a simple string, so that a nested par
	block, when we scanned it for variables, didn't have any
	translated b/c they weren't stored as variables.  This was fixed
	by creating a new Ptree derived object with a proper Translate
	method.  Added par5 to test this.

2004-06-23  Brian Kahne  <bkahne@ibmoto.com>

	* Fixed problems w/having plasma statements in inlined-methods.

2004-06-22  Brian Kahne  <bkahne@ibmoto.com>

	* Fixed bugs:

	1. We weren't migrating the scheduling thread from a busy
	processor to the new processor chosen.  Fixed this by adding to
	QBase a prev pointer and adding a remove function to Queue that
	lets a thread be removed in O(1) time.  This allows Cluster::busy
	to remove the scheduling thread from where it was and add it to
	the new processor.

	2. Fixed bug w/pfor:  We weren't supporting on blocks.

	3. Added a Processors class, which is just a vector of Processor
	objects.  However, the constructor lets you create N unique
	processors.  Just creating a vector and giving it Processor() as
	an argument means that you'd end up with an array all pointing to
	the same Proc.

2004-06-18  Brian Kahne  <bkahne@ibmoto.com>

	* Added mutex I/O routines which mirror the printf suite.  Still
	don't have a good solution for cout- probably just need to wrap it
	in a macro with pLock()/pUnlock() calls.

	* Added the Timeout class.  This is a channel that will deliver a
	value in an alt block after a specified amount of time (using
	pDelay).  Example:

		Timeout t(20);
		alt {
		  t.port() { cout << "Got a timeout!" << endl; }
		}

	The constructor requires a timeout value; this may be changed or
	read via methods.  No useful value is returned via the port, so
	you normally wouldn't map the return to a value.

	* Fixed a bug in Cluster::update_time():  If we updated the time
	and added a delay thread, it was possible that the thread had been
	terminated, so it wouldn't be added.  So we'd end up adding an
	empty processor to the processor queue, which would cause us to
	exit.  Fixed this by checking that at the end, _curproc has
	something to run.  If not, we mark the processor as waiting and
	try again.

	* Added the ability to start a thread with an explicit priority.
	This is done as follows:

	1.  Optional second argument to the on block:

		par {
		  on (pCurProc(),0) { /* thread 1 */ }
		  on (pCurProc(),1) { /* thread 2 */ }
      		  { /* thread 3 */ }
      		  { /* thread 4 */ }
    		}

	You have to supply two arguments to "on", so you need to use
	pCurProc() if you want to launch a thread on the same processor
	with a specific priority.

	2.  Optional second argument to spawn:  

		spawn(foo(),0);

	A priority of -1 may be used to specify the current thread's priority.

2004-06-17  Brian Kahne  <bkahne@ibmoto.com>

	* Integrated the Boehm-Demers-Weiser (BDW) garbage collector into
	Plasma.  This is now used by the thread library and available to
	the user.  To use it, derive an object from gc or allocate using
	the placement value (GC).

	For example:  new (GC) int[1000];

	or 

	class A : public gc { };

	You can freely mix managed and unmanaged memory.  To have a
	destructor called, derive from "gc_cleanup".  In general, do not
	delete managed memory- you can do it, but why bother when the
	garbage collector will collect it.

2004-06-11  Brian Kahne  <bkahne@ibmoto.com>

	* Added timeslicing of lowest-priority threads when busy is
	allowed.  This was accomplished by:

	1.  The threads now store relative time and start time. 

	2.  The busy() function loops until all required busy time is
	consumed.  This allows us to handle busy threads that are
	interrupted and timeslicing.

	3.  Time-sliced busy threads are added to the busy queue with a
	busy time of ConfigParms::_simtimeslice.  The busy function then
	loops until the entire time value is consumed.

2004-06-04  Brian Kahne  <bkahne@ibmoto.com>

	* Added time model:

	pDelay():  Puts current thread on the delay queue.  When time
	advances up to this point, process is removed and added back to
	processor.  Processor is added back to ready queue.  If processor
	is busy, then it's only added back to ready queue if priority of
	delayed process is higher than the process which made the
	processor busy.  In that case, the processor is added back, but
	removed as soon as higher priority process is finished.

	pBusy():  Puts current process and processor on the busy queue.
	When time advances up to this point, processor is put back into
	the ready processor queue.

	Time advances whenever there is no more work to be done for the
	current time step, i.e. no more processors are on the processor
	ready queue.  In that case, we advance to the next time step,
	which is the smaller of the tops of the delay and the busy queue.
	These queues are implemented as STL priority queues, so whenever
	we push on a value, the smallest item percolates to the top.

	pTime():  Returns current time of the system.

	If we set ConfigParms::_busyokay to false (default), then we
	cannot use pBusy; it will cause the system to abort.  This also
	means that preemptive thread switching is enabled.  If we set this
	value to true, we can use pBusy, but preemption is turned off- the
	only way that a thread swaps out is by a call to pBusy(),
	pDelay(), or a blocking operation (pWait(), alt, etc.).
	
	Note:  Time slicing not yet implemented.

2004-06-02  Brian Kahne  <bkahne@ibmoto.com>

	* Updated the scheduler to work in the way described by Pete
	Wilson: 

	A procesor works until all of its threads are finished,
	then a new processor is selected.  If none are available, we
	exit.  The scheduling thread hops to whatever the current
	processor is, so we know that there's always a thread to yield to.

	This means that we do *not* timeslice between processors, only
	between threads in the current processor.  As before, we respect
	priorities.

	To implement this, each Proc class has a state variable.  When we
	add a processor (Cluster::add_proc) we set its state to Running
	and add it to the Cluster's processor ready queue.  The scheduler
	calls update_proc before it gets the next thread to run- this
	checks to see if the current processor has any threads.  If not,
	we set its state to Waiting and we get another processor, exiting
	if no more exist.

	Each Thread now has a pointer to its parent processor, which we
	use to ensure that when a thread is awoken, its processor is on
	the run queue.  We can always call Cluster::add_proc b/c if the
	processor is already running, it's not added again.

	The scheduler thread, since it hops between processors, has its
	parent thread updated to the current processor by the scheduler,
	so that when we yield to it, it always takes us to the current
	processor.
	
2004-06-01  Brian Kahne  <bkahne@ibmoto.com>

	* Added the "on" block, which allows users to specify a target
	processor on which to run a statement within a par block:

	par {
	  on(p1) {
	    ....
	  }
	  on(p2) {
	    ...
	  }
	  {
	    ...
	  }
	}

	In the above, the first block runs on Processor p1, the second on
	Procesor p2, and the third on the current processor.

	Added a spawn pseudo-method to the Processor class::

		p1.spawn(foo(1,2));

	This spawns a new process on the specified processor.

2004-05-27  Brian Kahne  <bkahne@ibmoto.com>

	* Created the Processor class, which just wraps a Proc object.
	The user can instantiate Processor objects and supply the
	underlying Proc ptr to pSpawn.

	* The current scheduler architecture is as follows:

	- The Cluster object has a queue of Proc objects.  Each time the
	scheduler thread is run, it chooses another Proc with threads to
	run.  If none are available, we exit.

	- We add the current Proc to the Proc queue before we query
	again.  Thus, we do not discard empty Procs from the Proc queue-
	we simply cycle through the list.  This means that we don't need
	to store the Proc with a Thread when the Thread is waitinng on
	another Thread.

	- We get the thread to execute from the Proc object (respecting
	priorities) and swap to it.  This has the effect of passing the
	main scheduling thread amongst the processors, but it means that
	we timeslice between processors.

	* Pretty big re-org of the backend:  I renamed Processor to
	Cluster and created a new Proc class which stores the
	priority-ordered ready queues.  The Cluster object contains the
	scheduler and the queue of processors.  The scheduler picks a
	processor and then runs the next available thread from it.  The
	idea is that the Proc class will be exposed to users, whereas
	the Cluster will be kept hidden and will eventually map to each
	kernel thread (if we ever implement that).

	* The ThreadQ class was made into a generic Queue class which uses
	QBase as a container element.  Thread and Proc now derives
	from it and ThreadQ and ProcQ privately inherit from Queue, adding
	wrappers which do the appropriate pointer casting.

2004-05-26  Brian Kahne  <bkahne@ibmoto.com>

	* Added priorities to Plasma.  You can change the current thread's
	priority by calling pSetPriority() and you can get the current
	priority by calling pGetPriority().  Priorities are numbers 0 to
	n-1, where n is set in pSetup and defaults to 32.  0 is the
	highest priority, but internally 0 is the lowest, so that we can
	easily tell whether we should timeslice or not.  The idea is that
	we only timeslice on the lowest priority- all other threads run to
	completion.

2004-05-25  Brian Kahne  <bkahne@ibmoto.com>

	* Changed port statement syntax to be more clear.  Now, the format
	is:

	  <expr>.port(<decl>) { ... }

	or

	  <expr>->port(<decl>) { ... }
	
	* Added support for varargs handling with mutex classes.  The
	support isn't perfect, though:  You can't write a true variadic
	function, e.g. foo(const char *fmt,..), because you can't pass the
	variable argument list.  Instead, you must write a va_list
	function directly, e.g. foo(const char *fmt,va_list ap).  Plasma
	will then create a variadic version and a v_list version for you
	that are wrapped with locking code.

	* Re-did alt/afor blocks.  You can now nest alt and afor blocks
	and we'll block on all of these items.  You can put and alt or an
	aforr inside of another alt, but only a single port statement may
	go inside of an afor, e.g.

	alt {
	  port () {
	  }
	  afor () {
	    port() {
	    }
	  }
	  alt {
	  }
	}

	We will treat this as one big alt block, allowing you to wait on
	multiple data structures and combine data structures with single
	elements.  This meant that I had to change the handle type used by
	pSleep and pWake from an integer to HandleType which is currently
	a pair of integers:  The first element designates the port block
	(case statement item) and the second element refers to the loop
	index (if an afor- ignored if an alt).

	I refactored the code so that generateAltBlock() generates all
	code, given a PortVect object.  This object is populated by a call
	to parseAltBody() or parseAforBody().  They call parseAltBlock(),
	which may recursively call the two parse-body functions.  Then,
	generateAltBlock() writes the setup code and calls
	generateAltBody(), which writes the case statement.

	Added chan10 to test the above.

2004-05-20  Brian Kahne  <bkahne@ibmoto.com>

	* Added exception safety to locking mechanism.

	* Added support for shared data structures.  To make a class
	shared, simply add a modifier of pMutex to the front of its
	declaration.  This will protect all public functions (except
	constructors and the destructor) with locking code.  Note that
	varargs functions are not supported because I don't know how to
	pass on the variable arguments to another function.

	To prevent a public function from being protected, add a modifier
	of pNoMutex to the front.

	Example:

		pMutex class Foo {
		public:
		  // Not protected.
		  Foo();
		  ~Foo();
		  // Protected.
		  int a();
		  // Not protected.
		  pNoMutex int b();
		private:
		  // Not protected.
		  int c();
		};

2004-05-19  Brian Kahne  <bkahne@ibmoto.com>

	* Added QueueChan, a queued channel classs.  This allows multiple
	producers to write to a single consumer.  You can set the maximum
	size of the queue, or just let it float.

2004-05-18  Brian Kahne  <bkahne@ibmoto.com>

	* A Result<T> object can now interface with an alt block by using
	ResChan<T>, which may be constructed directly from Result<T>.

	* I changed the architecture of how handles are returned.  A
	handle now lives in a thread, rather than as a single instance in
	a Processor.  When a thread terminates, it will now wake each
	waiter and set its handle to the terminating thread's handle.
	pSleep() then returns the current handle and it may be queried by
	calling pHandle().

	It may be necessary to expand this in the future to where the
	waiter queue stores a handle and a thread.  Right now, the
	limitation is that at most one alt block can wait on a channel.
	This is inline with how other channels work and doesn't apply to
	using Result directly, but we may want to expand it in the future.

	* Added support to spawn for handling function pointers and method
	pointers.  Spawn now supports the following ways to call a
	subroutine:

	1. Literal function call:       spawn(foo());
	2. Function pointer call:       p = foo; spawn(p());
	3. Method call w/reference:     spawn(a.b());
	4. Method call w/pointer:       spawn(a->b());
	5. Static method call:          spawn(A::b());
	6. Method pointer w/reference:  p = &A::b; spawn(a.*p());
	7. Method pointer w/pointer:    p = &A::b; spawn(a->*p());

2004-05-17  Brian Kahne  <bkahne@ibmoto.com>

	* Added support to spawn for handling member calls.

	* Initial implementation of spawn operator.  It currently only
	processes function calls.

	* Created Result template for storing data from a spawn operation.

2004-05-14  Brian Kahne  <bkahne@ibmoto.com>

	* Added pDone(const THandle), which returns true if the specified
	thread is finished.  

	* Added initial code to parser to parse spawn command.

	* Added C++-only spawn test to test spawn implementation concept.

2004-05-12  Brian Kahne  <bkahne@ibmoto.com>

	* Broke plasma.mc into multiple files.

	* Finished alt work- added exception cleanup code.

	* Modified looping alt so that if the loop index variable
	is not a simple built-in type (integer compatible), we'll create
	an auxiliary vector and store index values there.  The handle we
	store in each channel is the index of the corresponding entry in
	the vector.

2004-05-11  Brian Kahne  <bkahne@ibmoto.com>

	* Changed alt/port block to a new synax.  Now, it's:

	alt {
	  port([<value decl>];<channel>;) { <action> }
	  ...
	  [ { <default action> } ]
	}

	In other words, it's a for-loop style syntax for the port block
	and a full declaration is required; the type-inferencing wasn't
	working very well, so I just made it explicit.

	* Added plasma.h for Plasma interface stuff that we want users to
	have to explicitly include, e.g. channel classes, etc.

	* Moved all plasma interface stuff into the plasma namespace.

2004-05-10  Brian Kahne  <bkahne@ibmoto.com>

	* Initial version of alt added.  The syntax is:

	alt {
	  port(<channel>[,<variable]) { <action> }
	  ...
	  [ { <default action> } ]
	}

	We check each channel listed in a port directive.  If one is found
	ready, its action is executed.  If a variable is present in the
	port statement, the value read from the channel is mapped to the
	variable, which is in scope for the action code.  If the default
	action block is present, then if no channels are ready, it is
	executed.  Otherwise, if no channels are ready, the alt-block
	sleeps until a channel is ready.  The action associated with the
	ready channel is then executed.

2004-05-07  Brian Kahne  <bkahne@ibmoto.com>

	* Expanded plasma-interface.h with functions needed to channels.
	Added chan1 regression to test a primitive channel written
	directly in C++.

2004-05-06  Brian Kahne  <bkahne@ibmoto.com>

	* Started a user guide (doc/user-guide.rst) and a schedule
	(doc/schedule.rst).  The idea is that the schedule will be updated
	in advance and the user guide will be updated before a feature is
	committed.

2004-04-29  Brian Kahne  <bkahne@ibmoto.com>

	* Modified the implementation of pfor:  Instead of allocating
	space for the argument structure on the heap, I added a new
	version of pSpawn which allocates space on the stack structure,
	then copies data to this space.

	* Added support for the "pfor" construct.  Originally, this was to
	be called "par" too, but OpenC++ does not allow the same keyword
	to be used for multiple constructs.

	The usage is:

		pfor (<for-style condition>) {
		  <body>
		}

	<body> is launched as a thread for each iteration of the loop.
	Execution waits at the end of the loop until all threads
	complete.  A pfor loop currently requires that there be at least
	one declaration in the condition of the loop, e.g.

		pfor (int i = 0; i != 10; ++i) { ... }

	The reason for this is that anything declared in the loop
	condition is passed by value to the thread, while everything else
	is passed by reference in order to allow for side effects.
	Without the pass-by-value, the loop would complete (most likely)
	before any thread got scheduled, so every thread would see the
	same final value for the loop variable, rather than the value with
	which the thread was launched.  This seemed the best way to get
	around that undesirable behavior.

2004-04-27  Brian Kahne  <bkahne@ibmoto.com>

	* Added a parallel quicksort to the regression.

	* Fixed parser bug:  You can't make a pointer to a reference, so
	if we use a reference within a par block, we don't take a pointer
	to it- we just keep treating it as a reference.

	* Fixed problem with pAbort() and pExit():  They now immediately
	switch to the scheduler, which sees that a shutdown is requested
	and thus exits.

	* Plasma project should now build and pass its regression.

2004-04-23  Brian Kahne  <bkahne@ibmoto.com>

	*  Start of the plasma project.
